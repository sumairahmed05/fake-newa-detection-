# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gpLCR7ErtIHO1ho-M0jnmYNGpb1PXQFl
"""

# âœ… STEP 1: Install and Import Libraries
!pip install tensorflow scikit-learn pandas numpy

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow.keras import layers, models
from google.colab import files

# âœ… STEP 2: Upload CSV File
print("/content/fake_or_real_news 01")
uploaded = files.upload()

# âœ… STEP 3: Read CSV File
csv_name = list(uploaded.keys())[0]   # automatically get uploaded CSV name
data = pd.read_csv(csv_name)
print("âœ… Dataset Loaded Successfully!")
print("ğŸ“„ Columns:", data.columns)
print(data.head())

# âœ… STEP 4: Preprocess Dataset
# Check and fix column names
if 'text' not in data.columns:
    data.rename(columns={data.columns[0]: 'text'}, inplace=True)
if 'label' not in data.columns:
    data.rename(columns={data.columns[-1]: 'label'}, inplace=True)

# Convert labels (Fake/Real â†’ 0/1)
data['label'] = data['label'].map({'FAKE': 0, 'REAL': 1}).fillna(data['label'])

# Drop missing values if any
data = data.dropna()

X = data['text'].astype(str)
y = data['label'].astype(int)
print("âœ… Data cleaned successfully! Total rows:", len(data))

# âœ… STEP 5: TF-IDF Vectorization
tfidf = TfidfVectorizer(stop_words='english', max_features=5000)
X_tfidf = tfidf.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)
X_train_arr, X_test_arr = X_train.toarray(), X_test.toarray()
print("âœ… TF-IDF completed. Shape:", X_train_arr.shape)

# âœ… STEP 6: Build ANN Model
input_dim = X_train_arr.shape[1]
model = models.Sequential([
    layers.Input(shape=(input_dim,)),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# âœ… STEP 7: Train ANN Model
history = model.fit(X_train_arr, y_train, epochs=5, batch_size=32, validation_data=(X_test_arr, y_test))

# âœ… STEP 8: Evaluate Model
loss, accuracy = model.evaluate(X_test_arr, y_test)
print(f"\nâœ… Model Accuracy: {accuracy*100:.2f}%")

y_pred = (model.predict(X_test_arr) > 0.5).astype("int32")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# âœ… STEP 9: Test on New Example
def predict_news(news_text):
    news_tfidf = tfidf.transform([news_text]).toarray()
    prediction = (model.predict(news_tfidf) > 0.5).astype("int32")[0][0]
    return "ğŸ“° Real News" if prediction == 1 else "ğŸš¨ Fake News"

print("\nğŸ” Testing Example:")
print(predict_news("Government announces new digital education policy."))
print(predict_news("Aliens landed in Karachi last night!"))